# 可能的优化点

- 索引优化
- 表大小出现碎片，重建表结构
- 

# SQL语句执行过程

大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

## 连接器

sql执行过程中临时使用的内存管理在连接对象中，如果长连接积累下来，导致内存占用太大，被OOM掉，mysql异常重启，可采用：

- 定时断开长连接
- 执行完较大操作后，执行mysql_reset_connection来重新初始化连接资源，将连接恢复到刚创建状态

## 查询缓存

不太好用，因为可能数据失效很快，缓存根本用不上

## 分析器

词法和语法分析

## 优化器

开始执行sql之前，要先经过优化器的处理。

决定了使用哪个索引，以及join的时候决定表的连接顺序。

## 执行器

开始执行语句select * from T where ID = 10，对于无索引的查询，大致逻辑：

- 调用innoDB引擎接口取第一行，判断与where中条件是否一致，不是则跳过，是则将这行保存到结果集
- 调用引擎接口取下一行，重复相同判断逻辑，直到最后一行
- 将所有满足条件的行做成的记录作为结果集返回给客户端

对于有索引的表，执行逻辑也差不多。第一次调用“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。

数据库慢查询日志中rows_examined字段，表明这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。

在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。

# 日志模块

## redo log

innodb引擎特有的日志，将更新先写日志，再写磁盘，即WAL(write ahead logging)。

当一条记录需要更新时，先把记录写道redo log里，并更新内存，此时就算更新完成了（如果要更新的数据不在内存，则是更新在内存中的change buffer，并写redo log）。同时，适当时候，将操作记录更新到磁盘，比如空闲时候。

redo log大小可以配置，有了redo log，保证了数据库即使发生异常重启，通过redo log重放，之前提交的记录也不会丢失，称为crash-safe。

## binlog

server层也有自己的日志，即binlog(归档日志)。

binlog没有crash-safe的能力，只是记录的逻辑操作。

## 两者区别

- redo log为innodb引擎特有；binglog为server实现
- redo log为物理日志，记录的是”在某个数据页上做了什么修改“; binlog是逻辑日志，记录的是语句原始逻辑，比如”给ID为2的这行c字段值加一“
- redo log循环写，空间固定，会使用完；binlog追加写，写到一定大小后切换到下一个，不会覆盖之前日志

## 执行update语句流程

- 获取数据
- 写入新行
- 新行更新到内存
- 写入redolog， 处于prepare阶段
- 写入binlog
- 提交事务，redolog处于commit状态

使用两阶段提交，是因为redo log负责事务，binglog负责归档恢复，各司其职，相互配合，才保证了功能完整性。

如果不采用两阶段提交，可能出现写一个后另一个还没写入就发生崩溃，出现数据不一致的情况。

## sql语句变慢

更新语句时，更新完内存并写入redolog，就代表完成。

内存中脏页数据刷入到磁盘，称为flush，触发flush时机有：

- redolog满了，无法再写入redolog，此时所有更新操作，需要先等把redolog中内容同步到磁盘
- 系统内存不足，要淘汰一些内存页供别的使用，如果淘汰的是脏页，就要写入磁盘
- 空闲时候刷入磁盘
- 正常关闭刷入磁盘

redo log满了这种情况要尽量避免，正常情况下是”内存不够用，要将脏页写入磁盘“。

innoDB用缓冲池(buffer pool)管理内存，每当读取数据时，若不在内存，则要到缓冲池中申请一个数据页。这时候如果淘汰的是脏页，就要将其刷入磁盘，变成干净页后再复用。

因此，刷脏页是常态，但出现下面情况，会明显影响性能：

- 一个查询要淘汰的脏页太多，响应时间变长
- 日志写满，更新全部堵住，写性能将为0

采用控制脏页比例的机制来避免此情况。

**脏页控制策略**

设置innodb_io_capacity参数，一般设为磁盘io能力，用来控制刷脏页的能力，越大表示能力越强。

刷脏页的频率考量因素：

- 刷的太慢，内存脏页太多，redo log容易写满

因此系统根据脏页比例和redo log日志序号综合考量，选择一个合适速度来刷脏页。

因此：无论是因为查询请求触发了淘汰脏页，还是后台刷脏页逻辑占用io资源影响了更新语句，都会造成从业务断感知到mysql”抖动“了一下。

# 表的大小

## 表数据存放位置

表大小由表结构大小和表数据大小组成，表结构一般很小，我们只讨论表数据大小。

参数innodb_file_per_table控制表数据的存放位置：

- off：存放在系统共享表空间，跟数据字典放在一起
- on：每个InnoDB表数据存放在一个以.ibd为后缀文件

MySQL5.6.6之后，默认为on。

## 两种存放位置区别

- 存放在单独文件中时，当不需要此表时，drop命令会直接删除此文件，更易管理
- 存在在共享表空间，表被删除空间也不会被回收

## 数据删除流程

- 记录删除：标记此记录被删除，记录位置仍能被复用

- 整个页上记录被删除：此页标记为被删除，页能被复用

因此，delete语句只是标记记录或页为”可复用“，磁盘文件大小不会变化。

而这些删掉后没有被使用的空间，就像是”空洞“。

同理，插入和更新也会造成空洞。

## 重建表

为了消除空洞，需要重建表。

- 新建一个表，将原表记录按主键递增方式插入。由于是递增，因此数据更为紧凑，没有空洞。

缺点：插入过程中，原表不能有更新，否则数据会丢失。即不能online。

- MySQL5.6版本引入online DDL

流程大致为：扫描原表主键所有数据页，用记录生成临时文件，生成临时文件过程中对原表的操作记录到日志文件，最后将日志文件应用到临时文件，使用临时文件构建新表。

具体语句为： ```alter table T engine=InnoDB```  （5.6版本之前阻塞，5.6之后才是Online型）



## online和inplace

- 如果采用方法一，创建了一个临时表，server层能观察到
- 如果采用方法二，实在innodb引擎处创建了一个临时文件，整个DDL过程是在innodb完成。server端没有观察到数据挪动到临时表，是一个”原地“操作，就叫做inplace。

注意：

	1. inplace操作不一定就是online型，比如给innodb的一个表字段加全文索引，它是inplace操作，但阻塞了增删改操作
	1. DDL过程如果是online型的，那一定是inplace。（因为只有无感知，才会允许同时有各种增删改操作）



## alter table 、analyze和optimize

- 从 MySQL 5.6 版本开始，alter table t engine = InnoDB 就是online型的DDL重建表，可以有效减少空洞
- analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；
- optimize table t 等于 recreate+analyze



# 锁

## 分类

- 全局锁
- 表锁
- 行锁

## 全局锁

对整个实例加锁，比如，全局加读锁，以下语句将会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

``````
Flush tables with read lock (FTWRL)
``````

应用场景：**全库逻辑备份**。

缺点：业务停摆。

若想不停摆地使用全库备份，使用innodb引擎的事务性来保证一致性。官方自带mysqldump 使用参数–single-transaction，会开启一个事务，保证一致性。

## 表级锁

有两种表级锁：表锁、元数据锁。

**表锁语法**：

- 加锁：lock tables ... read/write
- 解锁：unlock tables

应用场景：不支持更细粒度的锁时使用。



**元数据锁(MDL)**，不需要显式使用，访问表时会自动加上。

- 对表做增删改查时，加MDL读锁
- 对表做结构变更时，加MDL写锁

原则，读与读之间不互斥，多个线程可同时读；读与写之间、写与写之间互斥，必须等一个操作完下一个才能操作。

以下测试为MySQL5.7.42版本

(1) alter table执行前有人占有MDL读锁不释放，则alter table阻塞，且后续申请的读请求也被阻塞。

| 时刻 | 事务A                                       | 事务B                                               | 事务C                                       | 事务D                                         |
| ---- | :------------------------------------------ | --------------------------------------------------- | ------------------------------------------- | --------------------------------------------- |
|      | start transaction with consistent snapshot; | start transaction with consistent snapshot;         | start transaction with consistent snapshot; |                                               |
| T1   | select * from users;                        |                                                     |                                             |                                               |
| T2   |                                             | alter table users add column score int;<br />(阻塞) |                                             |                                               |
| T3   |                                             |                                                     | select * from users;<br />（阻塞）          |                                               |
| T4   | commit;                                     | 仍然阻塞                                            | 不阻塞                                      |                                               |
| T5   |                                             |                                                     |                                             | begin;<br />select * from user;<br />（阻塞） |
| T6   |                                             | 不阻塞                                              | commit                                      | 不阻塞                                        |
|      |                                             |                                                     |                                             |                                               |

在MySQL5.7之后的版本中，使用了online DDL，它的步骤如下：

1. 拿MDL写锁

2. 拿到后降级成MDL读锁

3. 真正做DDL

4. 做完之后升级成MDL写锁

5. 释放MDL锁

可以看到，在2~4之间，由于降级成了读锁，因此其他线程可以对其做增删改查(也是MDL读锁)操作，但如果执行到第4步时，其他线程做的增删改查操作还没做完（比如事务中还没提交），那么它们还拥有读锁，此时第四步就会阻塞住等待，等待它们都完成提交后才执行结束。

如果在升级成MDL写锁的等待期间又来新的增删改查请求，同样会被阻塞住。等之前的增删改查提交后，升级MDL写锁成功并释放锁，这些后来的请求就不被阻塞了。

图中，T2时刻事务B想要获取写锁，此时事务A拥有读锁，被阻塞；

T3时刻事务C要获取读锁，此时事务B正在请求写锁，请求写锁拥有优先级，事务C被写锁阻塞；

T4时刻，事务A提交，释放了读锁，事务B获取写锁，获取后马上降级成了读锁，因此事务C不阻塞了；

T5时刻之前，事务B完成了DDL，准备升级为写锁，但此时事务C的读锁没释放，因此被阻塞；

T5时刻，又来一个请求，但此时准备升回写锁的DDL阻塞，因此它也阻塞。

T6时刻，影响DDL升回写锁的事务C提交，事务B成功升级为写锁，完成DDL并释放锁，因此不阻塞；同时被写锁影响的事务D也不阻塞了。



alter table执行前无人占有MDL读锁，但有事务开启：

| 时刻 | 事务1                                                        | 事务2                                                       |
| ---- | ------------------------------------------------------------ | ----------------------------------------------------------- |
|      | start transaction with consistent snapshot;                  | start transaction with consistent snapshot;                 |
| T1   |                                                              | alter table users add column score int;<br />(正常执行成功) |
| T2   | select * from users;<br />报错Table definition has changed, please retry transaction |                                                             |

| 时刻 |      |      |
| ---- | ---- | ---- |
|      |      |      |
|      |      |      |
|      |      |      |

**案例**：给小表加字段，加字段的操作放在长事务中，加字段时就会申请DML写锁，事务不结束，DML锁不释放，导致后续所有的读请求都失败。

解决方案：

- 加字段前之前将所有的长事务都kill掉，防止加字段被阻塞
- 如果这个表是请求频繁的表，使用NoWait / Wait语法，设定一个超时时间，失败就挑选时间再试，避免影响新请求



## 行锁

行锁在在存储引擎实现，InnoDB 是支持行锁的，MyISAM 引擎不支持，这也是这也是 MyISAM 被 InnoDB 替代的重要原因之一。

优化使用行锁，可以**通过减少锁冲突来提升业务并发度**。

### 两阶段锁

|                            事务A                             |                   事务B                    |
| :----------------------------------------------------------: | :----------------------------------------: |
| begin;<br />update T set k=k+1 where id=1;<br />update t set k=k+1 where id=2; |                                            |
|                                                              | begin;<br />update t set k=k+2 where id=1; |
|                           commit;                            |                                            |

事务B的执行会被阻塞住，知道事务A提交之后才能继续执行。

因此，事务A持有两个记录的行锁，且是在commit之后才释放。

**也就是说，在innoDB中，行锁是在需要的时候才加的，但并不是不需要了就立即释放，而是要等到事务结束时才释放。这就是两阶段锁协议。**

知道这个设定，在使用事务时，就可以做一些优化：

**如果事务中需要锁多行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。这样保证该行锁在事务中被持有的时间最短。**



### 死锁和死锁检测

| 事务A                                      | 事务B                          |
| ------------------------------------------ | ------------------------------ |
| begin;<br />update t set k=k+1 where id=1; | begin;                         |
|                                            | update t set k=k+1 where id=2; |
| update t set k=k+1 where id=2;             |                                |
|                                            | update t set k=k+1 where id=1; |

事务A在等待id=2的行锁释放，事务B等待id=1的行锁释放，它们互相等待对方持有的资源释放，就是进入了死锁状态。

出现死锁后，有两种策略：

- 一种是直接进入等待，直到超时，超时时间通过参数innodb_lock_wait_timeout设定
- 另一种是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

innodb中，死锁默认超时时间为50s，也就是说出现死锁后，要超过50s后才有被锁住的线程退出，然后其他线程继续执行。这个长时间往往无法接受。但时间设置太小也不合适，万一就是正常的锁等待，如果设置很短就会出现误判。

另一个主动死锁检测，innodb_deadlock_detect 的默认值本身就是 on，它可以快速发现死锁，但会有额外负担。

如果是热点行数据更新，**很多事务都更新的是同一行**这种场景，死锁检测会消耗大量的CPU资源，该怎么处理？

**一种是，如果确保这个业务不会出现死锁，就临把死锁检测关掉。**不过这个操作有风险，因此死锁并不是错误，出现了大不了就回滚，业务重试就可以了，是业务无损的。而如果关掉了，就会出现大量超时，变成了业务有损。

**另一种，控制业务并发度，如果同一行只有很少的线程同时在更新，那么死锁检测的成本就会很低。**

这样在数据库服务端控制住同时访问的数量，可以通过中间件，MySQL源码等方面考虑。主要思路就是，对于相同行的更新，在进入引擎前排队。

还有一种，也可以通过将一行该为逻辑上的多行。比如影院营业额的记录，可以由一行改为10行，总额为这10个记录的总和。这样更新时，随机选择一条记录更新，这样锁冲突概率减小，减少死锁检测的cpu消耗。



# 索引

## 普通索引 or 唯一索引?

在不同的业务场景下，应该选择普通索引，还是唯一索引？

从性能考虑，选择唯一索引还是普通索引呢？选择的依据是什么呢？

**查询**：select id from T where k = 5, 查询性能微乎其微

- 普通索引查询到满足条件的第一个记录后，需要查找下一条记录，直到碰到第一个不满足k=5的记录
- 唯一索引，查找到满足条件的第一个记录后就停止

**更新：**

更新一个数据时，如果在内存中直接更新，如果不在内存中，在不影响数据一致性的前提下，innodb将更新操作缓存在change buffer中，不需要从磁盘中读入这个数据页。下次需要访问此数据页时，将数据页读入内存，并执行change buffer中与此页有关的操作。

后台线程也会定期将change buffer中数据merge到磁盘上。

如果能够将更新操作先记录在change buffer，减少读磁盘，就能提高语句执行速度。





当要插入的数据不在内存中时，使用普通索引，可充分利用change buffer特性，而唯一索引，则必要要读取磁盘到内存，判断要插入的数据的数据是否冲突。

**change buffer最好的适用场景：**

往change buffer中写入的数据越多，之后一次性merge到磁盘，则收益越大。

因此对于写多读少，页面在写完之后马上被访问的概率比较小，此时效果最好，常见账单类日志类系统。

**change buffer和bin log有什么区别？**

redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。



## mysql选错索引

**开启慢查询日志:**

``````
# 查看慢查询日志是否开启
msyql> show variables like '%slow_query_log%';
+---------------------+------------------------------+
| Variable_name       | Value                        |
+---------------------+------------------------------+
| slow_query_log      | OFF                          |
| slow_query_log_file | /var/lib/mysql/bird-slow.log |
+---------------------+------------------------------+

# 开启慢查询日志
set global slow_query_log=1;

# 查看默认慢查询时间阈值
mysql> show variables like 'long_query_time%';

# 设置，调试观察语句执行时间时设置为0
set long_query_time=1;
``````

**索引选择原则：**

删除历史数据和新增数据的场景，mysql会选错索引。

选择索引是优化器的工作，目的是找到最优方案，用最小代价执行语句，代价有：

- 扫描行数：扫描行数越少，意味访问磁盘次数越少，消耗cpu越少
- 是否使用临时表
- 是否排序
- 是否回表

**扫描行数的判断**

- 索引上不同值称为基数，越大区分度越好
- 使用show index from t查看基数， 但往往不准确
- 基数影响了扫描行数，使用explain查看预计扫描行数
- 使用analyze table t 命令，重新统计索引信息

通过查看索引基数，来确定是否使用这个索引，如果基数太小，就会弃用索引；再看使用此所有后要扫描的行数、回表、子查询等，最后优化器根据预估的成本决定是否走这个索引。

**索引异常和处理**

- 采用force index强制选择一个索引
- 修改sql语句，引导mysql使用希望的索引
- 新建更合适索引，或者删除误用的索引











# 事务的隔离性

## 隔离级别

SQL标准的事务隔离级别：读未提交(read uncommitted)、读提交(read committed)、可重复读(repeatable read)、串行化(serializable)。

- 读未提交：一个事务还没提交时，它做的变更就已经能被别的事务看到
- 读提交：一个事务提交之后，它做的变更才会被其他事务看到
- 可重复读：一个事务执行过程中看到的数据，总是跟它在启动时看到的数据是一致的。在此级别下，未提交的变更数据同样对别的事务不可见。
- 串行化：对同一行数据，写加写锁，读加读锁。出现读写冲突时，后访问的事务必须等待前一个事务执行完成，才能继续执行。

多个事务同时执行，可能会产生脏读、不可重复读、幻读的情况。

**启动事务时，创建一个视图(read-view)，每个记录更新会生成多个版本，这就是数据库的多版本并发控制，这样每个事务都可以读到自己版本能看到的数据，提高并发能力。**

每条记录更新时都会记录一个“回滚”操作，长事务会导致很老的事务视图，回滚记录也会很大，导致大量占用存储空间。



## 事务的启动方式

- 显示启动，使用begin、commit、rollback
- set autocommit=0，关闭自动提交，那么即使一个select语句也代表一个事务，且需要手动commit

建议开启autocommit，如果多个事务连续执行，可使用commit work and chain语法。

查询长事务：

``````
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
``````



## 事务隔离的实现

在“可重复读”级别下，事务在启动的时候就“拍了个快照“，称为一致性视图，即事务ID，它按照时间顺序递增。

每行数据有自己的版本号，是row trx_id， 每次数据更新，会被赋值为本次事务ID。

事务启动时，创建一个数组，保存了此事务启动瞬间，当前正在**活跃的事务ID**，即启动了但还没提交。

数组中最小值为低水位，当前系统已创建过的事务ID最大值+1为高水位。当前事务的一致性视图(read-view)，就是由此数组和高水位构成，而**版本的可见性规则，就是基于数据的row trx_id和此视图得到的**。

此视图启动后，中间过程的它观测到的数据，其可见性无非这几个逻辑

- 数据的row trx_id 低于低水位，说明事务启动时它是不活跃的因而不在数组中，则数据可见
- 数据的row trx_id 高于高水位，说明是后来系统又生成的，属于未来的事务生成的数据，则数据不可见
- 数据的row trx_id 在低和高之间，如果在数组中，则表明是事务启动时那些未提交的事务生成的数据，不可见；如果不在数组中，表示是**已提交的事务**生成的，可见。

ps : 高水位和数组中的最大值是一个吗？ 

不是，数组是系统已创建过的事务ID+1，比方说创建了100和101两个事务，但101已经提交了，100还没提交，因此高水位取的是101+1，数组取得100（99号事务启动，取得未提交数组100？但99号怎么会比100后启动呢？）



有了这个声明之后，在事务A中，其他事务创建的数据，要么属于是事务A启动时没提交的事务数据，落在数组里；要么是事务A启动后再启动的数据，高于高水位，都是不可见的。这样就达成了”其他事务的修改对本事务不可见“的效果。



## 幻读







"快照读"(snapshot read)和”当前读“(current read)。



# sql执行慢

(1)  查询语句长时间无结果返回

``````
select * from users;
``````

大概率是有其他线程拥有表上的MDL写锁，比如在做一个DDL操作，模拟一下

| session A               | session B            |
| ----------------------- | -------------------- |
| lock table users write; |                      |
|                         | select * from users; |

查看当前线程情况：

``````
mysql> show processlist;
+----+------+-----------+-------+---------+------+---------------------------------+---------------------+
| Id | User | Host      | db    | Command | Time | State                           | Info                |
+----+------+-----------+-------+---------+------+---------------------------------+---------------------+
| 47 | root | localhost | audio | Sleep   |    4 |                                 | NULL                |
| 48 | root | localhost | NULL  | Query   |    0 | starting                        | show processlist    |
| 49 | root | localhost | NULL  | Sleep   |   96 |                                 | NULL                |
| 50 | root | localhost | audio | Query   |    1 | Waiting for table metadata lock | select * from users |
+----+------+-----------+-------+---------+------+---------------------------------+---------------------+
``````

可以看到Id为50的该条查询语句状态为等待MDL锁，这个锁是被Id为47的线程持有的。我们开启wait检测：

``````
# 查看是否开启wait检测
mysql> select * from performance_schema.setup_instruments where name='wait/lock/metadata/sql/mdl';
+----------------------------+---------+-------+
| NAME                       | ENABLED | TIMED |
+----------------------------+---------+-------+
| wait/lock/metadata/sql/mdl | NO      | NO    |
+----------------------------+---------+-------+

# 开启performance_schema检测
mysql> update performance_schema.setup_instruments set ENABLED='YES', TIMED='YES' where name='wait/lock/metadata/sql/mdl';


``````

开启后，可查询造成MDL等待的线程号：

``````
# 查询被造成阻塞的process id
mysql> select* from sys.schema_table_lock_waits;
+---------------+-------------+-------------------+-------------+-----------------+-------------------+-----------------------+---------------------+--------------------+-----------------------------+-----------------------------+--------------------+--------------+------------------+----------------------+------------------------+-------------------------+------------------------------+
| object_schema | object_name | waiting_thread_id | waiting_pid | waiting_account | waiting_lock_type | waiting_lock_duration | waiting_query       | waiting_query_secs | waiting_query_rows_affected | waiting_query_rows_examined | blocking_thread_id | blocking_pid | blocking_account | blocking_lock_type   | blocking_lock_duration | sql_kill_blocking_query | sql_kill_blocking_connection |
+---------------+-------------+-------------------+-------------+-----------------+-------------------+-----------------------+---------------------+--------------------+-----------------------------+-----------------------------+--------------------+--------------+------------------+----------------------+------------------------+-------------------------+------------------------------+
| audio         | users       |                76 |          50 | root@localhost  | SHARED_READ       | TRANSACTION           | select * from users |                 86 |                           0 |                           0 |                 73 |           47 | root@localhost   | SHARED_NO_READ_WRITE | TRANSACTION            | KILL QUERY 47           | KILL 47                      |
+---------------+-------------+-------------------+-------------+-----------------+-------------------+-----------------------+---------------------+--------------------+-----------------------------+-----------------------------+--------------------+--------------+------------------+----------------------+------------------------+-------------------------+------------------------------+

``````

可以看pid为47，使用`kill 47`杀死此线程。

(2) 等flush

flush table: Closes all open tables, forces all tables in use to be closed, and flushes the query cache. FLUSH TABLES also removes all query results from the query cache, like the RESET QUERY CACHE statement.

关闭所有打开的表，强制所有在使用的表关闭，刷新查询缓存。同时从查询缓存中清楚所有查询结果，就像RESET QUERY CACHE语句一样。

因为，sql语句在执行前，都会打开表对象，如select * from t1语句，会找到t1表的frm文件，并打开表内存对象。为了控制表对象使用的内存空间和其他资源，MySQL会隐式（后台表对象管理线程）或显式（flush tables等）来关闭已打开但并没有使用的表对象。

但是，**正在使用的表对象是不能被关闭的（如sql请求正在运行）**，因此flush table操作会**被正在运行的sql请求阻塞**。

因此，flush table操作可认为是**table表的表级排它锁，会阻塞其他会话在此表上的操作**。

``````
flush tables t; # 关闭表t
flush tables;   # 关闭所有表
# 有with lock则加读锁，需要unlock 表后才能对表做update操作
flush tables t with read lock; # 关闭表t并给表加读锁
flush tables with read lock;   # 关闭所有表并给所有表加读锁
``````

基于以上特性，如果flush table期间























