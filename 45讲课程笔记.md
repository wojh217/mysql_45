# 可能的优化点

- 索引优化
- 表大小出现碎片，重建表结构
- 

# SQL语句执行过程

![image-20230714113536284](C:\Users\leadcom\AppData\Roaming\Typora\typora-user-images\image-20230714113536284.png)

大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

## 连接器

负责建立连接、获取权限、维持和管理连接。因为连接过程比较复杂，为了提高效率，通常使用长连接，即一次连接，多次查询。

但长连接容易导致mysql内存增长过快，这是因为sql执行过程中使用的内存要等连接关闭才释放，如果一直不关，则积累下来会很大，严重时导致程序OOM掉。解决方法：

- 定时断开长连接： 每过一段时间或者执行一个占用内存大的查询后，断开连接。
- 5.7版本后，可执行mysql_reset_connection来重新初始化连接资源，将连接恢复到刚创建状态。

**问题**

- mysql能够支持多少个连接？

```sql
mysql> show variables like 'max_connections';
+-----------------+-------+
| Variable_name   | Value |
+-----------------+-------+
| max_connections | 151   |
+-----------------+-------+
```

max_connections 参数控制同时存在的连接数上限，超过这个上限，系统就会返回Too many connections， 拒绝之后的请求。

- innodb_thread_concurrency参数又是什么？

控制并发查询线程数，一旦并发线程数达到这个值，接收到新请求后，就会进入等待状态，直到有线程退出让出空位。等待行锁、间隙锁的线程不计其中。

建议把它设置为64-128之间的值，因为如果不限制，则并发查询太多时，cpu调度切换的成本高。

- 短连接风暴怎么处理？

在短连接模型中，如果数据库处理的慢一些， 连接数就会暴涨，肯快超过max_connections大小。

- 有时候连接时速度很慢，卡半天是怎么回事？

## 查询缓存

不太好用，因为可能数据失效很快，缓存根本用不上

## 分析器

词法和语法分析

## 优化器

开始执行sql之前，要先经过优化器的处理。

决定了使用哪个索引，以及join的时候决定表的连接顺序。

## 执行器

开始执行语句select * from T where ID = 10，对于无索引的查询，大致逻辑：

- 调用innoDB引擎接口取第一行，判断与where中条件是否一致，不是则跳过，是则将这行保存到结果集
- 调用引擎接口取下一行，重复相同判断逻辑，直到最后一行
- 将所有满足条件的行做成的记录作为结果集返回给客户端

对于有索引的表，执行逻辑也差不多。第一次调用“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。

数据库慢查询日志中rows_examined字段，表明这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。

在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。



# 数据查询过程

## server层

在server层，从引擎获取到的数据，经历如下步骤发给客户端：

- 一行一行数据写入net_buffer
- 写满后通过tcp协议栈发出，即通过tcp_socket_send_buffer发出
- 客户端通过tcp协议栈接收，即通过tcp_socket_receive_buffer接收
- 客户端从接收缓冲区获取完后，mysql收到ack，清空net_buffer和发送缓冲区，继续读取一行行记录，再写入net_buffer，重复上述过程

由此可见，如果客户端迟迟没有从接收缓冲区获取数据，或者接收数据的速度跟不上发送的速度(比如业务逻辑中，是对每一行数据做复杂处理后，才处理下一行数据)，那么mysql发送方的发送效率就会收到影响。

比如测试，接收方一直不处理数据，则通过```show processlist```显示状态为```send to client```, 表示发送缓冲区满，数据发送被阻塞。

如果net_buffer够大，要查询的数据可一次性写入net_buffer，则不管发送缓冲区能不能写的下，也不管客户端是否及时将消息取走，server都认为事务已经结束，因为剩下的工作是由协议栈处理的。因此，如果想要快速减少```send to client```这个状态的话，增到net_buffer_length是个不错的做法。

**问题**： 我自己做测试，go连接sql数据库查数据时，超过120秒后才读取结果集，但是60s后在服务端show processlist就没有这个连接了，被服务方主动关闭了，然后120秒后，rows只能读取到原客户端接收缓冲区内的数据量大小。

# 日志模块

## redo log

innodb引擎特有的日志，将更新先写日志，再写磁盘，即WAL(write ahead logging)。

当一条记录需要更新时，先把记录写到redo log里，并更新内存，此时就算更新完成了（如果要更新的数据不在内存，则是更新在内存中的change buffer，并写redo log）。同时，适当时候，将操作记录更新到磁盘，比如空闲时候。

redo log大小可以配置，有了redo log，保证了数据库即使发生异常重启，通过redo log重放，之前提交的记录也不会丢失，称为crash-safe。

## binlog

server层也有自己的日志，即binlog(归档日志)。

binlog没有crash-safe的能力，只是记录的逻辑操作。

## 两者区别

- redo log为innodb引擎特有；binglog为server实现
- redo log为物理日志，记录的是”在某个数据页上做了什么修改“; binlog是逻辑日志，记录的是语句原始逻辑，比如”给ID为2的这行c字段值加一“
- redo log循环写，空间固定，会使用完；binlog追加写，写到一定大小后切换到下一个，不会覆盖之前日志

## 执行update语句流程

- 获取数据
- 写入新行
- 新行更新到内存
- 写入redolog， 处于prepare阶段
- 写入binlog
- 提交事务，redolog处于commit状态

使用两阶段提交，是因为redo log负责事务，binglog负责归档恢复，各司其职，相互配合，才保证了功能完整性。

如果不采用两阶段提交，可能出现写一个后另一个还没写入就发生崩溃，出现数据不一致的情况。

## sql语句变慢

更新语句时，更新完内存并写入redolog，就代表完成。

内存中脏页数据刷入到磁盘，称为flush，触发flush时机有：

- redolog满了，无法再写入redolog，此时所有更新操作，需要先等把redolog中内容同步到磁盘
- 系统内存不足，要淘汰一些内存页供别的使用，如果淘汰的是脏页，就要写入磁盘
- 空闲时候刷入磁盘
- 正常关闭刷入磁盘

redo log满了这种情况要尽量避免，正常情况下是”内存不够用，要将脏页写入磁盘“。

innoDB用缓冲池(buffer pool)管理内存，每当读取数据时，若不在内存，则要到缓冲池中申请一个数据页。这时候如果淘汰的是脏页，就要将其刷入磁盘，变成干净页后再复用。

因此，刷脏页是常态，但出现下面情况，会明显影响性能：

- 一个查询要淘汰的脏页太多，响应时间变长
- 日志写满，更新全部堵住，写性能将为0

采用控制脏页比例的机制来避免此情况。

**脏页控制策略**

设置innodb_io_capacity参数，一般设为磁盘io能力，用来控制刷脏页的能力，越大表示能力越强。

刷脏页的频率考量因素：

- 刷的太慢，内存脏页太多，redo log容易写满

因此系统根据脏页比例和redo log日志序号综合考量，选择一个合适速度来刷脏页。

因此：无论是因为查询请求触发了淘汰脏页，还是后台刷脏页逻辑占用io资源影响了更新语句，都会造成从业务断感知到mysql”抖动“了一下。

# 表的大小

## 表数据存放位置

表大小由表结构大小和表数据大小组成，表结构一般很小，我们只讨论表数据大小。

参数innodb_file_per_table控制表数据的存放位置：

- off：存放在系统共享表空间，跟数据字典放在一起
- on：每个InnoDB表数据存放在一个以.ibd为后缀文件

MySQL5.6.6之后，默认为on。

## 两种存放位置区别

- 存放在单独文件中时，当不需要此表时，drop命令会直接删除此文件，更易管理
- 存在在共享表空间，表被删除空间也不会被回收

## 数据删除流程

- 记录删除：标记此记录被删除，记录位置仍能被复用

- 整个页上记录被删除：此页标记为被删除，页能被复用

因此，delete语句只是标记记录或页为”可复用“，磁盘文件大小不会变化。

而这些删掉后没有被使用的空间，就像是”空洞“。

同理，插入和更新也会造成空洞。

## 重建表

为了消除空洞，需要重建表。

- 新建一个表，将原表记录按主键递增方式插入。由于是递增，因此数据更为紧凑，没有空洞。

缺点：插入过程中，原表不能有更新，否则数据会丢失。即不能online。

- MySQL5.6版本引入online DDL

流程大致为：扫描原表主键所有数据页，用记录生成临时文件，生成临时文件过程中对原表的操作记录到日志文件，最后将日志文件应用到临时文件，使用临时文件构建新表。

具体语句为： ```alter table T engine=InnoDB```  （5.6版本之前阻塞，5.6之后才是Online型）



## online和inplace

- 如果采用方法一，创建了一个临时表，server层能观察到
- 如果采用方法二，实在innodb引擎处创建了一个临时文件，整个DDL过程是在innodb完成。server端没有观察到数据挪动到临时表，是一个”原地“操作，就叫做inplace。

注意：

	1. inplace操作不一定就是online型，比如给innodb的一个表字段加全文索引，它是inplace操作，但阻塞了增删改操作
	1. DDL过程如果是online型的，那一定是inplace。（因为只有无感知，才会允许同时有各种增删改操作）



## alter table 、analyze和optimize

- 从 MySQL 5.6 版本开始，alter table t engine = InnoDB 就是online型的DDL重建表，可以有效减少空洞
- analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；
- optimize table t 等于 recreate+analyze



# 锁

## 分类

- 全局锁
- 表锁
- 行锁

## 全局锁

对整个实例加锁，比如，全局加读锁，以下语句将会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

``````
Flush tables with read lock (FTWRL)
``````

应用场景：**全库逻辑备份**。

缺点：业务停摆。

若想不停摆地使用全库备份，使用innodb引擎的事务性来保证一致性。官方自带mysqldump 使用参数–single-transaction，会开启一个事务，保证一致性。

## 表级锁

有两种表级锁：表锁、元数据锁。

**表锁语法**：

- 加锁：lock tables ... read/write
- 解锁：unlock tables

应用场景：不支持更细粒度的锁时使用。



**元数据锁(MDL)**，不需要显式使用，访问表时会自动加上。

- 对表做增删改查时，加MDL读锁
- 对表做结构变更时，加MDL写锁

原则，读与读之间不互斥，多个线程可同时读；读与写之间、写与写之间互斥，必须等一个操作完下一个才能操作。

以下测试为MySQL5.7.42版本

(1) alter table执行前有人占有MDL读锁不释放，则alter table阻塞，且后续申请的读请求也被阻塞。

| 时刻 | 事务A                                       | 事务B                                               | 事务C                                       | 事务D                                         |
| ---- | :------------------------------------------ | --------------------------------------------------- | ------------------------------------------- | --------------------------------------------- |
|      | start transaction with consistent snapshot; | start transaction with consistent snapshot;         | start transaction with consistent snapshot; |                                               |
| T1   | select * from users;                        |                                                     |                                             |                                               |
| T2   |                                             | alter table users add column score int;<br />(阻塞) |                                             |                                               |
| T3   |                                             |                                                     | select * from users;<br />（阻塞）          |                                               |
| T4   | commit;                                     | 仍然阻塞                                            | 不阻塞                                      |                                               |
| T5   |                                             |                                                     |                                             | begin;<br />select * from user;<br />（阻塞） |
| T6   |                                             | 不阻塞                                              | commit                                      | 不阻塞                                        |
|      |                                             |                                                     |                                             |                                               |

在MySQL5.7之后的版本中，使用了online DDL，它的步骤如下：

1. 拿MDL写锁

2. 拿到后降级成MDL读锁

3. 真正做DDL

4. 做完之后升级成MDL写锁

5. 释放MDL锁

可以看到，在2~4之间，由于降级成了读锁，因此其他线程可以对其做增删改查(也是MDL读锁)操作，但如果执行到第4步时，其他线程做的增删改查操作还没做完（比如事务中还没提交），那么它们还拥有读锁，此时第四步就会阻塞住等待，等待它们都完成提交后才执行结束。

如果在升级成MDL写锁的等待期间又来新的增删改查请求，同样会被阻塞住。等之前的增删改查提交后，升级MDL写锁成功并释放锁，这些后来的请求就不被阻塞了。

图中，T2时刻事务B想要获取写锁，此时事务A拥有读锁，被阻塞；

T3时刻事务C要获取读锁，此时事务B正在请求写锁，请求写锁拥有优先级，事务C被写锁阻塞；

T4时刻，事务A提交，释放了读锁，事务B获取写锁，获取后马上降级成了读锁，因此事务C不阻塞了；

T5时刻之前，事务B完成了DDL，准备升级为写锁，但此时事务C的读锁没释放，因此被阻塞；

T5时刻，又来一个请求，但此时准备升回写锁的DDL阻塞，因此它也阻塞。

T6时刻，影响DDL升回写锁的事务C提交，事务B成功升级为写锁，完成DDL并释放锁，因此不阻塞；同时被写锁影响的事务D也不阻塞了。



alter table执行前无人占有MDL读锁，但有事务开启：

| 时刻 | 事务1                                                        | 事务2                                                       |
| ---- | ------------------------------------------------------------ | ----------------------------------------------------------- |
|      | start transaction with consistent snapshot;                  | start transaction with consistent snapshot;                 |
| T1   |                                                              | alter table users add column score int;<br />(正常执行成功) |
| T2   | select * from users;<br />报错Table definition has changed, please retry transaction |                                                             |

| 时刻 |      |      |
| ---- | ---- | ---- |
|      |      |      |
|      |      |      |
|      |      |      |

**案例**：给小表加字段，加字段的操作放在长事务中，加字段时就会申请DML写锁，事务不结束，DML锁不释放，导致后续所有的读请求都失败。

解决方案：

- 加字段前之前将所有的长事务都kill掉，防止加字段被阻塞
- 如果这个表是请求频繁的表，使用NoWait / Wait语法，设定一个超时时间，失败就挑选时间再试，避免影响新请求



## 行锁

行锁在在存储引擎实现，InnoDB 是支持行锁的，MyISAM 引擎不支持，这也是这也是 MyISAM 被 InnoDB 替代的重要原因之一。

优化使用行锁，可以**通过减少锁冲突来提升业务并发度**。

### 两阶段锁

|                            事务A                             |                   事务B                    |
| :----------------------------------------------------------: | :----------------------------------------: |
| begin;<br />update T set k=k+1 where id=1;<br />update t set k=k+1 where id=2; |                                            |
|                                                              | begin;<br />update t set k=k+2 where id=1; |
|                           commit;                            |                                            |

事务B的执行会被阻塞住，知道事务A提交之后才能继续执行。

因此，事务A持有两个记录的行锁，且是在commit之后才释放。

**也就是说，在innoDB中，行锁是在需要的时候才加的，但并不是不需要了就立即释放，而是要等到事务结束时才释放。这就是两阶段锁协议。**

知道这个设定，在使用事务时，就可以做一些优化：

**如果事务中需要锁多行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。这样保证该行锁在事务中被持有的时间最短。**



### 死锁和死锁检测

| 事务A                                      | 事务B                          |
| ------------------------------------------ | ------------------------------ |
| begin;<br />update t set k=k+1 where id=1; | begin;                         |
|                                            | update t set k=k+1 where id=2; |
| update t set k=k+1 where id=2;             |                                |
|                                            | update t set k=k+1 where id=1; |

事务A在等待id=2的行锁释放，事务B等待id=1的行锁释放，它们互相等待对方持有的资源释放，就是进入了死锁状态。

出现死锁后，有两种策略：

- 一种是直接进入等待，直到超时，超时时间通过参数innodb_lock_wait_timeout设定
- 另一种是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

innodb中，死锁默认超时时间为50s，也就是说出现死锁后，要超过50s后才有被锁住的线程退出，然后其他线程继续执行。这个长时间往往无法接受。但时间设置太小也不合适，万一就是正常的锁等待，如果设置很短就会出现误判。

另一个主动死锁检测，innodb_deadlock_detect 的默认值本身就是 on，它可以快速发现死锁，但会有额外负担。

如果是热点行数据更新，**很多事务都更新的是同一行**这种场景，死锁检测会消耗大量的CPU资源，该怎么处理？

**一种是，如果确保这个业务不会出现死锁，就临把死锁检测关掉。**不过这个操作有风险，因此死锁并不是错误，出现了大不了就回滚，业务重试就可以了，是业务无损的。而如果关掉了，就会出现大量超时，变成了业务有损。

**另一种，控制业务并发度，如果同一行只有很少的线程同时在更新，那么死锁检测的成本就会很低。**

这样在数据库服务端控制住同时访问的数量，可以通过中间件，MySQL源码等方面考虑。主要思路就是，对于相同行的更新，在进入引擎前排队。

还有一种，也可以通过将一行该为逻辑上的多行。比如影院营业额的记录，可以由一行改为10行，总额为这10个记录的总和。这样更新时，随机选择一条记录更新，这样锁冲突概率减小，减少死锁检测的cpu消耗。



# 索引

## 普通索引 or 唯一索引?

在不同的业务场景下，应该选择普通索引，还是唯一索引？

从性能考虑，选择唯一索引还是普通索引呢？选择的依据是什么呢？

**查询**：select id from T where k = 5, 查询性能微乎其微

- 普通索引查询到满足条件的第一个记录后，需要查找下一条记录，直到碰到第一个不满足k=5的记录
- 唯一索引，查找到满足条件的第一个记录后就停止

**更新：**

更新一个数据时，如果在内存中直接更新，如果不在内存中，在不影响数据一致性的前提下，innodb将更新操作缓存在change buffer中，不需要从磁盘中读入这个数据页。下次需要访问此数据页时，将数据页读入内存，并执行change buffer中与此页有关的操作。

后台线程也会定期将change buffer中数据merge到磁盘上。

如果能够将更新操作先记录在change buffer，减少读磁盘，就能提高语句执行速度。





当要插入的数据不在内存中时，使用普通索引，可充分利用change buffer特性，而唯一索引，则必要要读取磁盘到内存，判断要插入的数据的数据是否冲突。

**change buffer最好的适用场景：**

往change buffer中写入的数据越多，之后一次性merge到磁盘，则收益越大。

因此对于写多读少，页面在写完之后马上被访问的概率比较小，此时效果最好，常见账单类日志类系统。

**change buffer和bin log有什么区别？**

redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。



## mysql选错索引

**开启慢查询日志:**

``````
# 查看慢查询日志是否开启
msyql> show variables like '%slow_query_log%';
+---------------------+------------------------------+
| Variable_name       | Value                        |
+---------------------+------------------------------+
| slow_query_log      | OFF                          |
| slow_query_log_file | /var/lib/mysql/bird-slow.log |
+---------------------+------------------------------+

# 开启慢查询日志
set global slow_query_log=1;

# 查看默认慢查询时间阈值
mysql> show variables like 'long_query_time%';

# 设置，调试观察语句执行时间时设置为0
set long_query_time=1;
``````

**索引选择原则：**

删除历史数据和新增数据的场景，mysql会选错索引。

选择索引是优化器的工作，目的是找到最优方案，用最小代价执行语句，代价有：

- 扫描行数：扫描行数越少，意味访问磁盘次数越少，消耗cpu越少
- 是否使用临时表
- 是否排序
- 是否回表

**扫描行数的判断**

- 索引上不同值称为基数，越大区分度越好
- 使用show index from t查看基数， 但往往不准确
- 基数影响了扫描行数，使用explain查看预计扫描行数
- 使用analyze table t 命令，重新统计索引信息

通过查看索引基数，来确定是否使用这个索引，如果基数太小，就会弃用索引；再看使用此所有后要扫描的行数、回表、子查询等，最后优化器根据预估的成本决定是否走这个索引。

**索引异常和处理**

- 采用force index强制选择一个索引
- 修改sql语句，引导mysql使用希望的索引
- 新建更合适索引，或者删除误用的索引











# 事务的隔离性

## 隔离级别

SQL标准的事务隔离级别：读未提交(read uncommitted)、读提交(read committed)、可重复读(repeatable read)、串行化(serializable)。

- 读未提交：一个事务还没提交时，它做的变更就已经能被别的事务看到
- 读提交：一个事务提交之后，它做的变更才会被其他事务看到
- 可重复读：一个事务执行过程中看到的数据，总是跟它在启动时看到的数据是一致的。在此级别下，未提交的变更数据同样对别的事务不可见。
- 串行化：对同一行数据，写加写锁，读加读锁。出现读写冲突时，后访问的事务必须等待前一个事务执行完成，才能继续执行。

多个事务同时执行，可能会产生脏读、不可重复读、幻读的情况。

**启动事务时，创建一个视图(read-view)，每个记录更新会生成多个版本，这就是数据库的多版本并发控制，这样每个事务都可以读到自己版本能看到的数据，提高并发能力。**

每条记录更新时都会记录一个“回滚”操作，长事务会导致很老的事务视图，回滚记录也会很大，导致大量占用存储空间。



## 事务的启动方式

- 显示启动，使用begin、commit、rollback
- set autocommit=0，关闭自动提交，那么即使一个select语句也代表一个事务，且需要手动commit

建议开启autocommit，如果多个事务连续执行，可使用commit work and chain语法。

查询长事务：

``````
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
``````



## 事务隔离的实现

在“可重复读”级别下，事务在启动的时候就“拍了个快照“，称为一致性视图，即事务ID，它按照时间顺序递增。

每行数据有自己的版本号，是row trx_id， 每次数据更新，会被赋值为本次事务ID。

事务启动时，创建一个数组，保存了此事务启动瞬间，当前正在**活跃的事务ID**，即启动了但还没提交。

数组中最小值为低水位，当前系统已创建过的事务ID最大值+1为高水位。当前事务的一致性视图(read-view)，就是由此数组和高水位构成，而**版本的可见性规则，就是基于数据的row trx_id和此视图得到的**。

此视图启动后，中间过程的它观测到的数据，其可见性无非这几个逻辑

- 数据的row trx_id 低于低水位，说明事务启动时它是不活跃的因而不在数组中，则数据可见
- 数据的row trx_id 高于高水位，说明是后来系统又生成的，属于未来的事务生成的数据，则数据不可见
- 数据的row trx_id 在低和高之间，如果在数组中，则表明是事务启动时那些未提交的事务生成的数据，不可见；如果不在数组中，表示是**已提交的事务**生成的，可见。

ps : 高水位和数组中的最大值是一个吗？ 

不是，数组是系统已创建过的事务ID+1，比方说创建了100和101两个事务，但101已经提交了，100还没提交，因此高水位取的是101+1，数组取得100（99号事务启动，取得未提交数组100？但99号怎么会比100后启动呢？）



有了这个声明之后，在事务A中，其他事务创建的数据，要么属于是事务A启动时没提交的事务数据，落在数组里；要么是事务A启动后再启动的数据，高于高水位，都是不可见的。这样就达成了”其他事务的修改对本事务不可见“的效果。



## 幻读

新建表：

``````

CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25);
``````

如下查询将会对哪些加锁?

``````
begin;
select * from t where d=5 for update;

# 再次查询
select * from t where d=5 for update;
commit;
``````

这条```select * from t where d=5 for update;```语句的含义是“给d=5的这些行加锁”，如果在此期间，其他事务修改了记录(比如将某行数据的d改为5)，或者新增了记录(比如插入了一行d为5的新记录)，那么再次查询时将会得到不一样的结果，这就产生了幻读。

(ps： 幻读只针对新增的记录，更新的记录不算幻读)

在repeatable read隔离隔离级别下，如果都是“快照读”，则不会出现幻读的情况。但如果使用了for update想要锁住某行，则使用了“当前读”，那么就有可能出现幻读。

那么这个for update锁，到底要锁些什么，才能避免幻读呢？



**在RR级别下，锁行的同时，也会使用间隙锁gap lock，统称为next-key lock**

加锁原则如下：

- 加锁基本单位为next-key lock， 也就是行锁和间隙锁，是一个前开后闭区间
- 查找过程中访问到的对象才会加锁
- 优化：索引上的等值查询，给唯一索引加锁时，next-key lock退化为行锁(因为唯一，也就不存在间隙的概念了)
- 优化：索引上的等值查询，向右遍历时且最后一个值不满足等值的条件，next-key 退化为间隙锁
- 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止

首先，间隙锁怎么加？

(1) 对于没有where字句的for update，或者没有走索引的for update，则锁的是整张表。

```
mysql> begin;
mysql> select * from t for update;
mysql> select * from t where d=5 for update;
```

因为这两个语句都会扫描全表，因此锁整张表，此时表上用update或者insert都会阻塞。

(2) 主键上的where查询

``````
mysql> begin;
mysql> select * from t where id=5 for update;
``````

- id为5的主键存在，行锁 + 间隙锁，间隙为与下一个主键值的间隙
- id为5的主键不存在，间隙锁

(3) 非唯一索引

``````
mysql> select id from t where c=5 lock in share mode;
``````

注意**只有访问到的对象才会加锁**，c上有索引，而这里查询使用了覆盖索引，因此只在c上加了行锁和间隙锁。

主键索引上没有加任何锁，因此如果通过主键来访问对象，不会被锁：

``````
mysql> update t set d=d+1 where id=5;
``````

当然，使用了lock in share mode只锁住了覆盖索引，但是如果用for update则不一样，它会给主键上满足条件的行加上行锁。



【小结】

1. 在业务中使用for update字句时，是想锁住某些行，不想别的线程同时在修改
2. 锁住某些行肯定有where 条件，那么这个条件就有这些情况

- 主键的某个具体值，比如where id=10，那没说的，就是这行，有可能还会有间隙锁
- 主键的范围，行锁 + 区间锁

这两种情况，真的达成了我们的目的，因为要修改、插入时，真的会被锁住

- 普通索引列的某个值，比如where c=10, 锁的是c索引的行，会不会锁主键？应该也是锁的，但主键只有行锁，c可能还有区间锁
- 普通索引的范围，那普通索引是行锁+区间锁，主键只有行锁吗？

这两种情况下，普通索引也达成了目的，锁住了指定区间范围内的值改动，但如果在范围外插入了数据，还是会发生幻读；



# sql执行慢

## 查询长时间不返回

(1)  查询语句长时间无结果返回

``````
select * from users;
``````

大概率是有其他线程拥有表上的MDL写锁，比如在做一个DDL操作，模拟一下

| session A               | session B            |
| ----------------------- | -------------------- |
| lock table users write; |                      |
|                         | select * from users; |

查看当前线程情况：

``````
mysql> show processlist;
+----+------+-----------+-------+---------+------+---------------------------------+---------------------+
| Id | User | Host      | db    | Command | Time | State                           | Info                |
+----+------+-----------+-------+---------+------+---------------------------------+---------------------+
| 47 | root | localhost | audio | Sleep   |    4 |                                 | NULL                |
| 48 | root | localhost | NULL  | Query   |    0 | starting                        | show processlist    |
| 49 | root | localhost | NULL  | Sleep   |   96 |                                 | NULL                |
| 50 | root | localhost | audio | Query   |    1 | Waiting for table metadata lock | select * from users |
+----+------+-----------+-------+---------+------+---------------------------------+---------------------+
``````

可以看到Id为50的该条查询语句状态为等待MDL锁，这个锁是被Id为47的线程持有的。我们开启wait检测：

``````
# 查看是否开启wait检测
mysql> select * from performance_schema.setup_instruments where name='wait/lock/metadata/sql/mdl';
+----------------------------+---------+-------+
| NAME                       | ENABLED | TIMED |
+----------------------------+---------+-------+
| wait/lock/metadata/sql/mdl | NO      | NO    |
+----------------------------+---------+-------+

# 开启performance_schema检测
mysql> update performance_schema.setup_instruments set ENABLED='YES', TIMED='YES' where name='wait/lock/metadata/sql/mdl';


``````

开启后，可查询造成MDL等待的线程号：

``````
# 查询被造成阻塞的process id
mysql> select* from sys.schema_table_lock_waits;
+---------------+-------------+-------------------+-------------+-----------------+-------------------+-----------------------+---------------------+--------------------+-----------------------------+-----------------------------+--------------------+--------------+------------------+----------------------+------------------------+-------------------------+------------------------------+
| object_schema | object_name | waiting_thread_id | waiting_pid | waiting_account | waiting_lock_type | waiting_lock_duration | waiting_query       | waiting_query_secs | waiting_query_rows_affected | waiting_query_rows_examined | blocking_thread_id | blocking_pid | blocking_account | blocking_lock_type   | blocking_lock_duration | sql_kill_blocking_query | sql_kill_blocking_connection |
+---------------+-------------+-------------------+-------------+-----------------+-------------------+-----------------------+---------------------+--------------------+-----------------------------+-----------------------------+--------------------+--------------+------------------+----------------------+------------------------+-------------------------+------------------------------+
| audio         | users       |                76 |          50 | root@localhost  | SHARED_READ       | TRANSACTION           | select * from users |                 86 |                           0 |                           0 |                 73 |           47 | root@localhost   | SHARED_NO_READ_WRITE | TRANSACTION            | KILL QUERY 47           | KILL 47                      |
+---------------+-------------+-------------------+-------------+-----------------+-------------------+-----------------------+---------------------+--------------------+-----------------------------+-----------------------------+--------------------+--------------+------------------+----------------------+------------------------+-------------------------+------------------------------+

``````

可以看pid为47，使用`kill 47`杀死此线程。

(2) 等flush

flush table: Closes all open tables, forces all tables in use to be closed, and flushes the query cache. FLUSH TABLES also removes all query results from the query cache, like the RESET QUERY CACHE statement.

关闭所有打开的表，强制所有在使用的表关闭，刷新查询缓存。同时从查询缓存中清楚所有查询结果，就像RESET QUERY CACHE语句一样。

因为，sql语句在执行前，都会打开表对象，如select * from t1语句，会找到t1表的frm文件，并打开表内存对象。为了控制表对象使用的内存空间和其他资源，MySQL会隐式（后台表对象管理线程）或显式（flush tables等）来关闭已打开但并没有使用的表对象。

但是，**正在使用的表对象是不能被关闭的（如sql请求正在运行）**，因此flush table操作会**被正在运行的sql请求阻塞**。

因此，flush table操作可认为是**table表的表级排它锁，会阻塞其他会话在此表上的操作**。

``````
flush tables t; # 关闭表t
flush tables;   # 关闭所有表
# 有with lock则加读锁，需要unlock 表后才能对表做update操作
flush tables t with read lock; # 关闭表t并给表加读锁
flush tables with read lock;   # 关闭所有表并给所有表加读锁
``````

基于以上特性，如果flush table时，正在有一个耗时的sql操作，则flush 操作被阻塞，接着后面其他的表操作（增删改查）则都被阻塞。

模拟如下：

| Session A               | Session B                   | Session C                                |
| ----------------------- | --------------------------- | ---------------------------------------- |
| select sleep(1) from t; |                             |                                          |
|                         | flush tables t;<br />(阻塞) |                                          |
|                         |                             | select * from t where id =1;<br />(阻塞) |

这里t表有10万行数据，则select sleep(1) 将耗时10万秒，事务B和C都被阻塞。

```
mysql> show processlist;
+----+------+-----------+-------+---------+------+-------------------------+------------------------------+
| Id | User | Host      | db    | Command | Time | State                   | Info                         |
+----+------+-----------+-------+---------+------+-------------------------+------------------------------+
| 48 | root | localhost | NULL  | Query   |    0 | starting                | show processlist             |
| 52 | root | localhost | audio | Query   |    2 | Waiting for table flush | select * from t where id = 1 |
| 54 | root | localhost | audio | Query   | 1323 | User sleep              | select sleep(1) from t       |
| 56 | root | localhost | audio | Query   |   34 | Waiting for table flush | flush tables t               |
+----+------+-----------+-------+---------+------+-------------------------+------------------------------+
```

这时候kill 56 和54，事务C就不会阻塞了。



（3）等行锁

查询时一个更新行的事务未提交，导致select被堵住。

| session A                                  | session B                   |
| ------------------------------------------ | --------------------------- |
| begin;<br />update t set c=c+1 where id=1; |                             |
|                                            | select * from t where id=1; |

通过sys.innodb_lock_waits表查询导致被锁的语句：

``````
mysql> select * from t sys.innodb_lock_waits where locked_table='`test`.`t`'\G
*************************** 1. row ***************************
                wait_started: 2023-07-07 17:36:33
                    wait_age: 00:00:39
               wait_age_secs: 39
                locked_table: `audio`.`t`
                locked_index: PRIMARY
                 locked_type: RECORD
              waiting_trx_id: 421145112075920
         waiting_trx_started: 2023-07-07 17:36:33
             waiting_trx_age: 00:00:39
     waiting_trx_rows_locked: 1
   waiting_trx_rows_modified: 0
                 waiting_pid: 59
               waiting_query: select * from t where id = 1 lock in share mode
             waiting_lock_id: 421145112075920:64:6:2
           waiting_lock_mode: S
             blocking_trx_id: 243674
                blocking_pid: 60
              blocking_query: NULL
            blocking_lock_id: 243674:64:6:2
          blocking_lock_mode: X
        blocking_trx_started: 2023-07-07 17:31:53
            blocking_trx_age: 00:05:19
    blocking_trx_rows_locked: 1
  blocking_trx_rows_modified: 2
     sql_kill_blocking_query: KILL QUERY 60
sql_kill_blocking_connection: KILL 60

``````

然后使用kill 60断开这个连接，此连接内的执行语句就会被回滚。用kill queury不行，因为update语句已经执行了。

## 查询慢

``````
mysql> select * from t where c=50000 limit 1;
``````

c字段上没有索引，语句使用id主键顺序扫描，因为limit 1条件，因此扫描到c为50000的一行后就停止。

(c字段上没有索引，那么查询期间整个表会被锁吗？)

``````
# 开启慢查询后，慢查询日志如下
# Time: 2023-07-09T04:32:14.141469Z
# User@Host: root[root] @ localhost []  Id:     9
# Query_time: 0.009672  Lock_time: 0.000099 Rows_sent: 1  Rows_examined: 50000
SET timestamp=1688877134;
select * from t where c=50000 limit 1;
``````

扫描了50000行，用时9.6毫秒。

这里是因为扫描行数多，因此执行慢。



还有一种只扫描一行，但是也慢。

| session A                                                    | session B                                    |
| ------------------------------------------------------------ | -------------------------------------------- |
| start transaction with consistent snapshot;                  |                                              |
|                                                              | update t set c=c+1 where id=1;（执行一万次） |
| select * from t where id=1;<br />select * from t where id=1 lock in share mode; |                                              |

这里不加锁的查询select * from t where id=1;耗时要比加锁的select * from t where id=1 lock in share mode查看慢，这是因为session B中执行了更新语句，不加锁则是快照读，需要更具undo log读取到历史版本，而加锁的当前读则直接读数据即可。



【小结】：sql执行慢，要么是因为锁的原因，导致长时间不返回，如表锁、行锁，要么是因为查询过程中，其他事务做了很多变更，导致查询一致性视图时需要回滚变慢。



# MySQL保证数据不丢

## binlog的写入机制

事务执行过程中，先把日志写入到binlog cache，事务提交时，再把cache写到binlog文件中。

一个事务的binlog不能拆分，因此不论这个事务有多大，也要保证一次性写入，这涉及到binlog cache的保存问题。

系统给binlog cache分配一个内存，每个线程一个，参数binlog_cache_size控制其大小，超过时，要暂存到磁盘。

写的过程：

写入binglog cache -> 通过write 写到page cache -> 通过fsync真正写入磁盘

其中write是写入到操作系统的page cache，fsync是真正写入磁盘。

sync_binlog控制write和fsync的时机：

- 为0，每次提交事务只write，不fsync
- 为1，每次提交事务都会执行fsync
- 为N，每次提交事务都write，但累计N个事务才fsync

出现IO瓶颈时，将其设置为一个比较大的值，可以提升性能。但风险时主机出现异常重启，会丢失最近N个事务的binglog日志。



## redo log的写入机制

事务在执行过程中，生成的redo log先写redo log buffer。

redo log的流程：

写入log buffer -> 写到page cache -> fsync真正写到磁盘

参数innodb_flush_log_at_trx_commit控制：

- 为0， 每次事务提交只把redo log留在redo log buffer中
- 为1， 每次提交直接持久化到硬盘
- 为2，每次提交只把redo log写道page cache

有一个后台线程，每隔一秒，会把redo log buffer中的日志，调用write写到page cache，然后调用fsync持久化到磁盘。

因此，一个没有提交的事务redo log，写到buffer中时，也会被后台线程持久化到磁盘。

- redo log buffer占用空间达到一定比例时，后台线程会主动写盘
- 并行的事务提交时，将这个事务的redo log buffer持久化到磁盘，如果里面有其他事务的未提交redo log，也会被持久化



两阶段提交时，先redo log prepare，再写bin log，最后redo log commit。

在双1策略中，即innodb_flush_log_at_trx_commit为1，sync_binlog也为1，则两阶段提交时，prepare阶段和bing log节点都需要持久化到磁盘，最后的commit只需要write到page cache就可以了。

采用组提交可以节约磁盘IOPS，因为一次写磁盘时写入了多个事务的redo log。

**如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？**

- 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。
- 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。
- 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。



# 如何保证主备一致？

## 主备结构

![image-20230710161541325](C:\Users\leadcom\AppData\Roaming\Typora\typora-user-images\image-20230710161541325.png)

主备结构，主节点可读可写，备节点只可读：

- 状态1时，A为主库，B为备库
- 状态2，完成主备切换，A为从库，B为主库

将备库设置为只读有以下好处：

- 在备库上查询可以防止误用写操作
- 防止主备切换时有bug，比如切换过程中出现双写，造成主备不一致
- 用readonly状态判断节点角色

**同步过程**：主-备之间维持一个长链接，主机写binlog后不断同步给备机。本机收到主机传过来的binlog，先写到本地文件，称为中转日志(relay log)，然后解析中转日志，执行其中的命令。

## binglog三种形式

- statemtn：原生的sql语句，使用这种模式有风险，因为同一条sql在主备上执行，可能结果是不同的，比如走不同的索引后排序的结果
- row：记录了要操作的具体哪一行，不会不一致的风险
- mixed：上面两种的混合，如果会引起主备不一致，则用row格式，否则用statement格式，比较节省空间

建议使用row格式，比如在恢复数据时，比较很方便的恢复过来，因为它完整地记录地要操作数据的行：

- delete时，binglog日志完整记录了删除的行，要恢复时，用insert 可直接恢复
- insert时，使用delete则可删除
- update时，binglog记录了update前和后的数据，也能轻易恢复

如果语句中有now这样的变量，则binglog中会设置一个now变量，然后记录整个sql。

因此binlog中是有上下文概念的，恢复数据时，不能只拷贝sql语句，要把整个文件都给mysql来执行。

``````
# master.000001 文件里面从第 2738 字节到第 2973 字节中间这段内容解析出来，放到 MySQL 去执行
mysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;
``````

## 双M结构与循环复制

![image-20230710164357211](C:\Users\leadcom\AppData\Roaming\Typora\typora-user-images\image-20230710164357211.png)

图中A、B互为主备，这样在切换时不用再修改主备关系。

主机生成binlog发给备机B，B执行完后也生成binlog，同样再发给A，这样就出现重复执行的情况（log_slave_updates 设置为 on后，备机执行relay log后也生成bin log）。

解决思路：

- 规定两个库的server id不同
- 备库收到binlog并重放的过程中，节点B生成的binlog中的server id也是A的server id
- 回传给节点A时，A判断回传数据中的server id是否与自己相同，相同则不再处理该日志



# MySQL保证高可用

正常情况下，只要主库的bin log能正常传递到备库并全部成功执行，则主备之间不会有数据差异，这就是最终一致性。

而高可用，只有最终一致性是不够的。

## 主备延迟

主备切换分为主动、被动形式。

主库和备库有几个时间点：

- 主库写入binlog，称为T1
- bin log传给备库，称为T2
- 备库执行完bin log，称为T3

T3-T1，就是主备延迟，在备库上使用```show slave status```命令，会显示当前备库延迟了多少秒，即seconds_behind_master.

它的计算方法为：

1. 每个事务的binlog里面都有一个时间，用于记录主库上写入的时间
2. 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到seconds_behind_master.



正常情况下，T2-T1的间隔很短，延迟的主要原因还是备库接受bin log后执行所耗费的时间。

所以，备库消费中转日志(relay log)的速度，比主库bin log速度还慢，就会造成明显的主备延迟。

- 备库机器性能差，或者备库上压力大，可采用一主多从模式，减轻备库读请求压力
- 大事务：事务必须完成才能写入bin log，如果事务执行时间过长，那么备库接收到bin log的时间就会滞后
- 大表DDL：建议采gh-ost方案
- 备库的并行复制能力

由于主备延迟的存在，因此在做主备切换时，有相应不同的策略：

在双M架构下，切换流程为：

1. 判定备库的seconds_behind_master延迟时间，在某个阈值范围内才允许进行主备切换操作
2. 把主库改为只读read only
3. 等待备库的seconds_behind_master值为0，表示所有binlog均已同步
4. 备库改为可读可写
5. 业务请求切换到备库B

这个流程保证了主备之间数据的一致性质，称为**”可靠性优先“**。

在第3步骤的等待时间，系统不可用，直到5才完成恢复。

**可用性优先**

如果不等seconds_behind_master值为0，直接执行4、5操作，则可能会出现数据不一致的情况。而使用row格式的bin log，则更容易发现不一致的情况。

在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。

##  备库的并行复制能力

备库采用多线程执行主库的binlog，并行复制遵循如下策略：

- 一个事务不能被拆分，必须放到一个worker中
- 更新同一行的两个事务，必须分发到同一个worker中

有以下集中策略：

- 按表并行
- 按行并行
- mysql5.6按库并行
- mariaDB的并行复制策略：组提交优化
- mysql5.7的并行：两阶段提交判断是否可以并行
- MySQL 5.7.22的按行并行策略

大事务不仅影响主库，也是造成备库复制延迟的主要原因之一。

## 主库出问题了，从库怎么办？

目前大多数都采用mysql一主多从结构：

![image-20230711095058958](C:\Users\leadcom\AppData\Roaming\Typora\typora-user-images\image-20230711095058958.png)

一主多从，用于读写分离，主库负责写和一部分读，其他读请求由从库分担。

A和A’互为主备，主备切换到B、C、D指向新的主库A‘。

主备切换后：

![image-20230711095324528](C:\Users\leadcom\AppData\Roaming\Typora\typora-user-images\image-20230711095324528.png)

在一主多从结构中，主备切换后，从库要指向新的主库，复杂性相应增加。

(1) 基于位点的主备切换

我们知道，把节点B设置为节点A'的从库时，要执行：

``````
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
MASTER_LOG_FILE=$master_log_name 
MASTER_LOG_POS=$master_log_pos  
``````

最后两个LOG_FILE和LOG_POS，表示要从哪个文件的哪个位置开始同步，即同步点。

相同的日志，在A和A‘上，位点是不同的(比如不相关联的事务，可能会并发执行)。B原来记录的是A的位点，现在进行主备切换，要重新找A’的位点。

一个大致的找A‘逻辑如下：

- 等待A’的所有中转日志完成同步
- 在 A’上执行 show master status 命令，得到当前 A’上最新的 File 和 Position
- 取原主库故障时刻T
- 用 mysqlbinlog 工具解析 A’的 File，得到 T 时刻的位点

但这种方法取得的位点是不精确的，比如该A‘位点之后的记录可能已经被从库B已同步了，就会报错Duplicate entry错误。

- 主动跳过一个事务
- slave_skip_errors 参数，直接设置跳过指定的错误

（2） GTID

Global Transaction Identifier， 全局事务验证，事务在提交时生成，事务的唯一标识，格式：

``````
GTID=server_uuid:gno
``````

server_uuid为实例的唯一凭证，gno为整数，每次事务提交+1.

在启动mysql实例时，加上参数gtid_mode=on 和 enforce_gtid_consistency=on 就可以了。

在GTID模式下，每个事务都会跟一个GTID一一对应。GTID有两种生成方式：

- gtid_netxt为automatic，代表使用默认值。把server_uuid:gno 分配给这个事务。

​		a. 记录binlog时，先记录一行 SET @@SESSION.GTID_NEXT=‘server_uuid:gno’;

​		b. 把这个GTID加入本实例的GTID集合

- gtid_next为一个指定的值，那么：

 		a. 如果该指定值已存在本实例的GTID集合中，则接下来的事务被忽略

​		 b. 如果该指定值不再本实例的GTID集合中，则将该值分配给接下来的事务

因此，每个实例都维护了一个GTID结合，对应着该实例”执行过的所有事务“。

**基于GTID的主备切换**

在GTID模式下，备库B要设置成为新主库A’的从库语法：

``````
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
master_auto_position=1 
``````

其中master_auto_position表示使用GTID协议。

这个协议下的切换流程：

- B指向新主库A‘，建立连接
- B把自己的GTID集合set_b发给A’
- A‘算出自己的GTID集合set_a和set_b的差值，判断自己本地是否有包含此差值的binlog事务：没有则返回报错，有则开始逐步发欸B



# 读写分离产生的问题

由于主从延迟，客户端执行完一个更新事务后马上发起查询，如果查询的是从库，则会读到刚刚事务提交之前的状态。

这种情况称为”过期读“，解决方案有以下几种：

- 强制走主库
- sleep方案
- 判断主备无延迟方案
- 配合semi-sync方案
- 等主库位点方案
- 等GTID方案

（1）强制走主库

如果请求必须要拿到最新的结果，那就强制发到主库上

(2)  sleep方案

预估一个主从同步消耗时间，发起请求时等待一段时间，问题就是不精确。

(3) 判断主备无延迟

比如从库读请求时，根据seconds_behind_master值是否为0，为0表示无延迟再执行查询请求。

又或者根据位点比较：Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos 这两组值完全相同。

又或者GTID比较：Retrieved_Gtid_Set和Executed_Gtid_Set相同

(4) semi-sync方案

上面判断主从无延迟，只能表示从库把收到的binglog都执行完了，但可能主库的有些binlog还没有传给从库。

semi-sync方案，要求主库上写入数据后，把bin log发给从库，从库回复ack后，才代表主库上事务完成。

注意这里是只要求一个从节点回复就可以了，因此如果多个从节点，那么在从节点上的查询，仍有过期读的情况。

再者，如果是必须等到从节点全部同步了主节点才允许查询，那么在业务高峰期，可能一致难以全部同步，从节点则一直不可用, 也就是过度等待。

(5) 等主库位点方案

为了解决过期读的问题，采用一种思路，就是在查询从库时，不必等从库全部同步完主库，而只需要同步了想要查询的数据就可以了。

``````
select master_pos_wait(file, pos[, timeout]);
``````

这个命令就是在从库上执行，file指主库文件名，pos指要同步截止的位置，timeout指超时。

返回值为整数M，表示从命令开始执行，要同步到指定的binlog位置，一共执行了多少事务。

- 如果执行期间出现异常，返回NULL
- 如果等待超时，返回-1
- 如果已经在这个位置了，就返回0.

因此对于主库上刚执行完的操作，如果要在空库上进行查询，可采用：

- 主库执行完成后，利用show master status查看当前的File 和 Position
- 选定一个从库进行查询，执行select master_pos_wait(file, pos,1); 超时设置1秒
- 如果返回值>=0, 则从此从库进行查询，否则从主库查询

(6) 等GTID方案

同等位点一样，也有一个函数：

``````
select wait_for_executed_gtid_set(gtid_set, 1);
``````

表示等主库的gtid_set。

MySQL 5.7.6 版本开始，允许在执行完更新类事务后，将这个事务的 GTID 返回给客户端。

你只需要将参数 session_track_gtids 设置为 OWN_GTID，然后通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值即可。

【小结】

由于主从延迟的存在，在从库上进行查询时，可能会产生过期读。普遍情况下，对请求进行分类，实时的请求可以走主库，然后从库查询可采用等位点、等GTID方案，但如果所有从库都延迟，则请求会落到主库上，主库压力会增大，甚至可能会打挂。



# 判断数据库是不是出问题了

- select 1: 只能说明库还在
- 查表判断：select * from mysql.heath_check;
- 更新判断

``````
mysql> update mysql.health_check set t_modified=now();
``````

为了防止主主备库双M结构时出现问题，使用多行语句：

``````
mysql> CREATE TABLE `health_check` (
  `id` int(11) NOT NULL,
  `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;

/* 检测命令 */
insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now();
``````

- 内部检测

使用performance_schema表提供的监控数值，比如超过某个请求时间

# join的使用

## 驱动表的选择

建立两张表t1和t2：

``````

CREATE TABLE `t2` (
  `id` int(11) NOT NULL,
  `a` int(11) DEFAULT NULL,
  `b` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `a` (`a`)
) ENGINE=InnoDB;

drop procedure idata;
delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=1;
  while(i<=1000)do
    insert into t2 values(i, i, i);
    set i=i+1;
  end while;
end;;
delimiter ;
call idata();

create table t1 like t2;
insert into t1 (select * from t2 where id<=100)
``````

（1） Index Nested-Loop Join

然后使用查询语句, 设置t1为驱动表，t2为被驱动表：

``````
select * from t1 straight_join t2 on (t1.a=t2.a);
``````

因为t2表上有索引，因此join的过程用上了索引，大致流程为：

- 从表t1读入一行数据R
- 从数据R中，取出a字段到表t2查询
- 取出t2中满足条件的行，跟R组成一行，作为结果集的一部分
- 重复执行1-3，直到t1的末尾循环结束

驱动表是走全表扫描，而被驱动表是走树搜索。假设驱动表N行，被驱动表M行，则时间复杂度```N+N*2*lgM```.

因此，如果被驱动表可以使用索引的化，最好用小表做驱动表。

这称为**Index Nested-Loop Join**。

（2）Simple Nested-Loop Join

如果使用没有索引的列作为join条件：

``````
select * from t1 straight_join t2 on (t1.a=t2.b);
``````

则每次t2匹配时，都要做一次全表扫描。这种总扫描行数就太多了

(3) Block Nested-Loop Join

mysql对此做了优化，当被驱动表上没有索引时，流程如下：

- 把表1的数据放入线程内存join_buffer 中，这里就是把整个表1放入内存
- 扫描表2，把表2的每一行取出，和join_buffer 中数据比较，满足条件，则作为结果集一部分返回

同(2)相比，总扫描行数不变，但由于是内存操作，速度会快一些。

如果join_buffer放不下，则采用分段放。把表1的一部分放入，然后表2的所有行逐一比较，然后再放下一段，再逐一比较。

同样的，选择相对小的表作为驱动表，总扫描次数会小。同样，join_buffer 越大，一次放入的数据越多，总扫描次数也小。

【小结】：

1. 要不是使用join？

如果可以用上被驱动表上的索引，那就没问题，也就是看explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样

2. 要使用join，该使用哪个表作为驱动表？

尽量使用小表，这里小表指的是数量数和字段数，比如where 条件限制了某个表数量，则它作为驱动表更合适；比如查询结果中只需要某个表的一两个字段，则它作为驱动表更合适。

## join优化

(1) 对NLJ算法的优化

**MRR查询优化**：在普通索引上的一个范围查询，先到足够多的主键id，然后排序后，去主键索引查询，体现”顺序获取“的优势。

根据MRR优化原理，MySQL5.6引入**BKA**(Batched Key Access)算法，来进行对NLJ的优化：

​		在NLJ 算法中，join时每次都是从表1中取一行记录去匹配表2，为此可以把表1中的一部分数据放到临时内存即join buffer中，一次性的去匹配表2的数据。

启动BKA算法方法，执行sql语句前：

```
set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
```

(2) 对BNL算法的优化

BNL算法对系统有几个影响：

- 多次扫描被驱动表，占用磁盘IO资源
- 判断join条件需要进行N*M次对比，非常占用cpu资源
- 可能会导致buffer pool的热数据被淘汰，影响内存命中率

一种情况下给被驱动表join字段加索引，变为BKA算法；

另外有一些不适合在被驱动表上建索引的情况：

``````
select * from t1 join t2 on (t1.b=t2.b) where t2.b>=1 and t2.b<=2000;
``````

如果这是一个低频查询，且表t2过滤后也没多少数据，这时为t2在b字段上添加索引有点浪费。

则可以考虑创建临时表：

``````
create temporary table tmp_t(id int primary key, a int, b int, index(b) ) engine=innodb;
insert into temp_t select * from t2 where t2.b>=1 and t2.b <=2000;
select * from t1 join temp_t on (t1.b=t2.b);
``````

临时表上b字段有索引，且数据量已经被过去掉。这样join就能走索引。

**hash join**

自己在业务端实现hash join：

- select * from t1; 将t1的数据存入自定义的hash结构中
- select * from t2 where b>=1 and b<=2000; 获取表 t2 中满足条件的 2000 行数据
- 把这2000行数据，一行行取到业务端，去hash结构中匹配

**思考题**

``````sql
CREATE TABLE `t1` (
 `id` int(11) NOT NULL,
 `a` int(11) DEFAULT NULL,
 `b` int(11) DEFAULT NULL,
 `c` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;

create table t2 like t1;
create table t3 like t2;
insert into ... //初始化三张表的数据
``````

一个三表join查询，应该如何加索引，来得到最快的执行速度？

```sql
select * from t1 join t2 on(t1.a=t2.a) join t3 on (t2.b=t3.b) where t1.c>=X and t2.c>=Y and t3.c>=Z;
```

第一原则是使用BKA算法，首先根据t1.c>=X t2.c>=Y  t3.c>=Z 这三个条件过滤数据，看t1、t2、t3哪个表的结果集小，选择小的那个作为驱动表；

第一种情况，如果t1或t3是驱动表，那剩下的连结部分就固定了：

- 如果t1是驱动表，则连结顺序为t1->t2->t3, 这时t2.a和t3.b上创建索引
- 如果t3是驱动表，则连结顺序为t3->t2->t1, 这时t2.b和t1.a上创建索引

同时，要在第一个驱动表上的字段c上创建索引；

第二种情况，如果选出来t2是驱动表，则需要评估另外两个条件的过滤效果。哪个小就哪个作为第二个驱动表。

总之，整体的思路就是，尽量让每一次参与 join 的驱动表的数据集，越小越好，因为这样我们的驱动表就会越小。





# 数据恢复

## 恢复方法

删除数据分类：

- 使用delete语句删除数据行
- 使用drop table 或者 truncate table删除表
- 使用drop database 语句删除数据库
- 使用rm命令删除整个mysql实例

(1) 误删行

只要binlog_format=row 和 binlog_row_image=FULL，那么binlog中就会有行操作记录， 通过flashback解析工具，反向执行binlog恢复数据。

预防误删：开始ql_safe_updates=on，则在delete或者update操作时，如果没有where条件会报错

这种方法不能使用drop/truncate table, drop database，因此这三种情况下，binlog中只有一个truncate/drop语句，没办法恢复。

(2) 误删库/表

使用全量备份+增量日志的方式恢复，要求定期全量备份和实时备份binlog。

- 取最近一次全量备份，用备份恢复出一个临时库
- 从日志库中，取出某个时间点后的日志
- 将日志中除了误删除的命令，其他全部使用mysqlbinlog命令应用到临时库

缺点：mysqlbinglog命令单线程解析，且不能只针对特定表

一种改进方案是：将全量备份恢复出的临时库，挂在某个备份节点下，通过change replication filter replicate_do_table = (tbl_name) 命令指定只同步某张表，且也能用上并行复制技术。

(3) 延迟复制备库

前面全量+增量日志的方式，如果日志比较大或者误操作距离上一次全量备份的时间较长，则恢复起来就会非常慢。

可以采用搭建延迟复制的备库，CHANGE MASTER TO MASTER_DELAY = N 命令，使备库与主库有N秒的延迟。这样主库误删后，备库还没操作，则备注执行stop slave， 然后通过前面的操作l来快速恢复。

(4) rm删除

只要搭建了高可用集群，一个节点的删除，会选出新的主库，保证集群的正常运行。

## 预防方法

- 账号分离
- 指定操作规范



# order by 排序

## 构建表和数据

```sql
CREATE TABLE `t_city` (
  `id` int(11) NOT NULL,
  `city` varchar(16) NOT NULL,
  `name` varchar(16) NOT NULL,
  `age` int(11) NOT NULL,
  `addr` varchar(128) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `city` (`city`)
) ENGINE=InnoDB;
```

构建数据的语句:

```go
package main

import (
	"bytes"
	"fmt"
	"math/rand"
	"os"
	"strings"
	"sync"
)

type PriId struct {
	m  sync.Mutex
	id int
}

func (p *PriId) GetId() int {
	p.m.Lock()
	defer p.m.Unlock()
	p.id++
	return p.id
}

func main() {
	p := &PriId{}

	var bf1 = new(bytes.Buffer)
	var bf2 = new(bytes.Buffer)
	var bf3 = new(bytes.Buffer)

	var wg sync.WaitGroup
	wg.Add(3)
	go func() {
		defer wg.Done()
		for i := 0; i < 4000; i++ {
			city := "Hangzhou"
			name := randomString(4)
			age := rand.Intn(90)
			addr := addrList[rand.Intn(len(addrList))]
			fmt.Fprintf(bf1, "insert into t_city (id, city, name, age, addr) values (%d, '%s', '%s', %d, '%s');\n", p.GetId(), city, name, age, addr)
		}
	}()

	go func() {
		defer wg.Done()
		for i := 0; i < 1000; i++ {
			city := "Beijing"
			name := randomString(4)
			age := rand.Intn(90)
			addr := addrList[rand.Intn(len(addrList))]
			fmt.Fprintf(bf2, "insert into t_city (id, city, name, age, addr) values (%d, '%s', '%s', %d, '%s');\n", p.GetId(), city, name, age, addr)
		}
	}()

	go func() {
		defer wg.Done()
		for i := 0; i < 1000; i++ {
			city := "Shanghai"
			name := randomString(4)
			age := rand.Intn(90)
			addr := addrList[rand.Intn(len(addrList))]
			fmt.Fprintf(bf3, "insert into t_city (id, city, name, age, addr) values (%d, '%s', '%s', %d, '%s');\n", p.GetId(), city, name, age, addr)
		}
	}()

	wg.Wait()
	fmt.Println("All done")

	file, err := os.OpenFile("insert.sql", os.O_CREATE, 0)
	if err != nil {
		fmt.Println(err)
		return
	}
	defer file.Close()

	bf1.WriteTo(file)
	bf2.WriteTo(file)
	bf3.WriteTo(file)

}

const charset = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"

var addrList = []string{
	"China", "London", "USA", "Russia", "Japan", "Canada", "Germany", "Holland",
}

func randomString(n int) string {
	sb := strings.Builder{}
	sb.Grow(n)
	for i := 0; i < n; i++ {
		sb.WriteByte(charset[rand.Intn(len(charset))])
	}
	return sb.String()
}

```

插入4000行Hangzhou数据，1000条Shanghai数据，1000条Beijing数据。

## 查看排序过程

查询city=Hangzhou，并按name排序的前1000条数据：

```sql
mysql> explain select city,name,age from t_city where city='Hangzhou' order by name limit 1000;
+----+-------------+--------+------------+------+---------------+------+---------+-------+------+----------+---------------------------------------+
| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref   | rows | filtered | Extra                                 |
+----+-------------+--------+------------+------+---------------+------+---------+-------+------+----------+---------------------------------------+
|  1 | SIMPLE      | t_city | NULL       | ref  | city          | city | 18      | const | 4000 |   100.00 | Using index condition; Using filesort |
+----+-------------+--------+------------+------+---------------+------+---------+-------+------+----------+---------------------------------------+
```

结果中：

- key为city，表示使用索引city
- rows为4000，表示扫描行数4000，也就是将所有city为Hangzhou的行都扫描了一遍
- Extra: Using index condition, 表示使用了索引下推?
- Using filesort： 表示需要排序

mysql给每个线程分配一块内存用于排序，称为sort_buffer, 排序的大致流程为：

1. 申请一块sort_buffer, 确定要放入的字段为city, name, age（称为全字段排序，与之对应的则只放待排序字段和主键字段）

2. 从索引city找到第一个city为Hangzhou的记录，找到主键ID

3. 从主键ID取出整行，取name,age,city三个字段的值，放入sort_buffer

4. 从所以city取下一个匹配记录的主键ID

5. 重复步骤3、4，直到city的值不满足条件为止
6. 对sort_buffer中的记录按照name进行快速排序
7. 将排序结果的前1000行返回给客户端

sort_buffer_size就是sort_buffer的大小。当要排序的数据量小于sort_buffer_size，排序就在内存中完成，否则需要磁盘临时文件辅助排序。

用下面的方法判断是否使用了临时文件：

```
/* 打开optimizer_trace，只对本线程有效 */
SET optimizer_trace='enabled=on'; 

/* @a保存Innodb_rows_read的初始值 */
select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';

/* 执行语句 */
select city, name,age from t_city where city='Hangzhou' order by name limit 1000; 

/* 查看 OPTIMIZER_TRACE 输出 */
SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G

/* @b保存Innodb_rows_read的当前值 */
select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';

/* 计算Innodb_rows_read差值 */
select @b-@a;
```

结果中number_of_tmp_files反应了使用临时文件的数量。

```
"filesort_summary": {
              "rows": 1001,
              "examined_rows": 4000,
              "number_of_tmp_files": 0,
              "sort_buffer_size": 66072,
              "sort_mode": "<sort_key, additional_fields>"
            }
```

examined_rows扫描行数，number_of_tmp_files排序临时文件数，sort_buffer_size为buffer大小，sort_mode中有排序字段和其他字段。

## 全字段排序和row_id排序

当要返回的字段很多时，由于buffer中要存放的字段太多，导致存放的行数量很少，因此要分成很多临时文件，排序性能会变差。

此时mysql会只把待排序字段和主键ID放在buffer中，等排序完成后，在根据主键ID回表查询要返回的字段

```
# 设置排序时行数据的长度，如果超过此长度，就换一个算法，即buffer内只保留待排序字段和rowid
SET max_length_for_sort_data = 16;
```

这种算法与前面相比，多了一次最后的回表，因此扫描行数是4000+1000=5000，同时buffer中存储的字段只有city和rowid。

```
"filesort_summary": {
              "rows": 1001,
              "examined_rows": 4000,
              "number_of_tmp_files": 0,
              "sort_buffer_size": 28032,
              "sort_mode": "<sort_key, rowid>"
            }
# @b-@a的值为5000
```

## 天然排序

如果从索引上取到的值，天然就是排序的，那么就不用再进行排序了。

比如，建立city和name的联合索引，那么根据city取到的数据，本身就是按照name已经排序好了，只需要根据rowid取的要返回的字段即可。

```
mysql> alter table t_city add index city_user(city, name);
mysql> explain select city, name,age from t_city where city='Hangzhou' order by name limit 1000;
+----+-------------+--------+------------+------+----------------+-----------+---------+-------+------+----------+-----------------------+
| id | select_type | table  | partitions | type | possible_keys  | key       | key_len | ref   | rows | filtered | Extra                 |
+----+-------------+--------+------------+------+----------------+-----------+---------+-------+------+----------+-----------------------+
|  1 | SIMPLE      | t_city | NULL       | ref  | city,city_user | city_user | 18      | const | 4000 |   100.00 | Using index condition |
+----+-------------+--------+------------+------+----------------+-----------+---------+-------+------+----------+-----------------------+
```

可以看到Extra中没有Using filesort，说明不需要排序，因为联合索引本身有序，其实也不用扫描完整的4000行，扫描1000行就够了(这里显示4000是预估扫描行数)。

再进一步，使用覆盖索引，city索引上直接包含要返回的字段，减少了回表查询这一步骤。

```
mysql> alter table t_city add index city_user_age(city, name, age);
mysql> explain select city, name,age from t_city where city='Hangzhou' order by name limit 1000;
+----+-------------+--------+------------+------+------------------------------+---------------+---------+-------+------+----------+--------------------------+
| id | select_type | table  | partitions | type | possible_keys                | key           | key_len | ref   | rows | filtered | Extra                    |
+----+-------------+--------+------------+------+------------------------------+---------------+---------+-------+------+----------+--------------------------+
|  1 | SIMPLE      | t_city | NULL       | ref  | city,city_user,city_user_age | city_user_age | 18      | const | 4000 |   100.00 | Using where; Using index |
+----+-------------+--------+------------+------+------------------------------+---------------+---------+-------+------+----------+--------------------------+
```

可以看到使用city_user_age这个联合索引，Extra中Using index表示使用了覆盖索引。

# 获取随机行数据

##  使用rand

```
mysql> select word from words order by rand() limit 3;
```

使用order by rand()的大致流程：

- 创建临时表
- 取出表words的每一行记录，算出一个0-1的随机值，插入到临时表
- 根据临时表的所有数据进行sorted_buffer排序
- 排序后取得3行记录

缺点：扫描行数为2 * 原表行数，并且还需要构建临时内存表。中间可能不采用归并排序，而采用优先级队列排序。



## 随机方法1

- 获取表主键id最大值M和最小值N
- 在M和N之间取随机数X
- select * from t where id >=X limit 1

缺点：原表id可能不连续，因此取的数不均匀

## 随机方法2

- 获取表行数N = count(*)
- 取一个不大于N的随机整数C
- select * from t limit C,1

优点：取记录均匀，但扫描行数比较多，为N + C

【课后题】取三个随机数，  按照之前取N+C方法取三个C，则总扫描行数会很多，该如何减少？

- 想办法让主键连续，采用方法1直接取三个随机值
- 取三个行数的随机值C1、C2、C3，且他们从小到达排序，则可以：

​	id1 = select id from t limit C1, 1;

​	id2 = select id from t where id>id1 limit C2-C1, 1;

​	id3 = select id from t where id >id2 limit C3-C2, 1;

总体思路和优化分页查询的类似，在前一次查询时拿到id，后一次分页则可以加上where条件，减少扫描行数。



# sql语句逻辑相同，性能差异大

## 索引列上使用函数

一个交易表语句：

``````

mysql> CREATE TABLE `tradelog` (
  `id` int(11) NOT NULL,
  `tradeid` varchar(32) DEFAULT NULL,
  `operator` int(11) DEFAULT NULL,
  `t_modified` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `tradeid` (`tradeid`),
  KEY `t_modified` (`t_modified`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
``````

假设，现在已经记录了从 2016 年初到 2018 年底的所有数据， 要统计所有年份7月份的交易总记录数，可能会这么写：

```sql
select count(*) from tradelog where month(t_modified)=7 ;
```

在索引列上使用函数，则破坏了索引的有序性，就只能走全表或全索引扫描，不能利用到索引的树搜索功能了，因此改为：

```
select count(*) from tradelog where (t_modified >= '2016-7-1' and t_modified<'2016-8-1') or (t_modified >= '2017-7-1' and t_modified<'2017-8-1') or (t_modified >= '2018-7-1' and t_modified<'2018-8-1');
```

有时优化器会偷懒，即使有些语句不破坏索引的有序性，它还是不会考虑索引。比如```select * from tradelog where id + 1 = 10000```, 因此最好不要在字段上加函数。

## 隐式类型转换

```
mysql> select * from tradelog where tradeid=110717;
```

tradeid本身是varchar类型，要和int类型比较。

在mysql中，字符串和数字比较，是将字符串转为数字，然后再进行比较。

因此，这个语句就相当于：

```
mysql> select * from tradelog where  CAST(tradid AS signed int) = 110717;
```

仍然是对索引字段做函数操作，放弃走索引树搜索。

```
select * from tradelog where id="83126";
```

这个语句就不走全表扫描了，因为是将“83126”转化为数字类型和，去索引树种搜索。

## 字符集不同

创建一个交易明细表：

```
mysql> CREATE TABLE `trade_detail` (
  `id` int(11) NOT NULL,
  `tradeid` varchar(32) DEFAULT NULL,
  `trade_step` int(11) DEFAULT NULL, /*操作步骤*/
  `step_info` varchar(32) DEFAULT NULL, /*步骤信息*/
  PRIMARY KEY (`id`),
  KEY `tradeid` (`tradeid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
```

其中它的字符集为utf8，那么使用如下语句：

```sql
mysql> select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/
```

这时，tradelog表为驱动表，要关联到trade_detail表时，d表的tradeid字段是utf8， 而l表是utf8mb4，是utf8的超集，因此默认是把utf转为utf8mb4，因此就会在d表的tradeid字段上做函数操作，因此不会走索引。

如果是下面这种连接关系：

```
mysql> select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and d.id=4; /*语句Q1*/
```

这时d表是驱动表，而被驱动表l的字段是超集，因此不会在l.tradeid上做函数操作，因此会利用到索引。

上面那条不走索引的语句可改为：

```
mysql> select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; 
```

主动把被驱动表要比较的类型统一，就不会出现在d.tradeid上做函数操作的事情了。

# 自增主键的使用

## 自增值的保存

表结构定义保存在后缀名为.frm的文件中，但是并不会保存自增值。

不同引擎对于自增值的保存策略不同：

- MyISAM引擎保存在文件中
- InnoDB保存在内存中，到MySQL8.0版本后，才有了”自增值持久化“的能力

MySQL5.7及以前的版本中，保存在内存中，并没有持久化。每次重启后，打开表时会去找表中已有的最大自增值，然后+1作为当前的子增值。

MySQL8.0版本，自增值记录在redo log中，重启时依靠redo log恢复自增值。

## 自增值修改机制

- 插入时自增值列指定为0，null或未指定，则当前表的AUTO_INCREMENT值填到自增字段
- 指定了具体的值，则直接使用

使用具体的值X时，根据X和当前表的自增值Y比较，插入后表的自增值可能会发生变化：

- 如果X<Y, 则不变
- 如果X>Y, 则当前表的自增值要根据自增初始值和步长，取一个最接近X但比X的新自增值

表自增值初始和步长均为1，因此如果X>Y，默认情况下新自增值为X+1。

``````
在一些情况下，初始值和步长不全是默认值，比如双M主备结构中，要求双写时，设置步长为2，让一个库的自增id为奇数，另一个库的自增id为偶数，避免两个库生成主键发生冲突。
``````

## 自增主键为什么不连续？

- insert 插入失败
- 事务中有insert语句，但roll back

这两种情况下，由于自增值不能回退，会导致自增主键不连续。

**为什么自增值不能回退？**

如果允许回退，就需要解决并发时主键冲突问题，从而导致并发能力严重下降。

## 自增锁优化

目前获取自增锁id，是申请完后马上释放，以便别的事务再申请。

而innodb_autoinc_lock_mode参数，可以控制这个行为：

- 为0，语句执行结束后才释放
- 为1，普通的insert语句，申请之后马上释放；insert...select这样的批量插入语句，要等语句结束后才释放
- 为2，所有申请自增主键的操作都是申请后就释放锁

因为insert...select这样的批量插入语句，事先是不知道要插入多少条数据，因此如果不等语句结束就释放锁，会导致同时也有插入操作时，该事务生成的id不连续，则如果bin log的statement格式备机执行出来的数据就会和主库不一致。

解决思路：

- insert...select这样的批量插入语句，等语句结束后再释放，保证了id的连续性
- binlog_format记录为row格式，innodb_autoinc_lock_mode仍然为2，这样备库执行不依赖自增主键去生成

这里的批量插入语句，包括insert...select、replace...select、load data语句。

对于批量插入语句，mysql会批量申请id：

- 第一次申请，分配1个
- 第二次申请，分配2个
- 第三次申请，分配4个
- 第四次森请，分配8个
- 以此类推

因此，这种情况下如果申请的数量大于真实使用的数量，也会出现id不连续的情况。

# 自增id用完了怎么办

## 表定义自增id

到达上限后，再申请下一个，值保持不变。

默认4字节无符号数的自增id，最大值42亿，如果有符号数，则是21亿多。

虽然自增id不是连续的，但对于删除不怎么频繁的表而言，整体上限可取10多亿是没问题的。而对于10多亿的数据量，一般不会放在一个表中，都会进行分库分表，也就是说，还没到达上限就被拆分了。

但如果真的要单表存储那么多数据，要么考虑自增id使用8字节的整数，这个数字绝对够用了。

那么可以在线修改表结构的id字段类型吗？

对于修改字段类型这种操作，是不支持并发DML的，也就是说，在修改期间，不允许对此表做delete、insert、update操作，直接alter是不行的。

**使用第三方工具online修改表结构**

- 使用gh-ost工具

**使用主从切换修改表结构**

- 从库表结构修改，然后进行主从切换

而分库分表时，不能依赖于每个表的自增ID来全局唯一标识这些数据了，要提供一 个全局唯一的ID号生成策略来支持分库分表的环境。



## InnoDB系统自增row_id

如果创建表时未指定主键，则系统为其创建一个长度为6字节的row_id。系统全局维护row_id值，所有无主键的表，都共享这个row_id。

则row_id范围为0~2^48-1, 到达上限后，下一个值为0，且能插入表，只是会覆盖原有数据。

因此，我们应该在建表时主动创建主键，这样到达上限时会报错，而不是默认覆盖。



## Xid

xid是redo log和bin log共有的字段，用来对应事务。

mysql内部维护一个全局变量global_query_id，每次执行语句将会从中取值，然后变量加1。如果语句是事务的第一条语句，则它就是事务的Xid。

global_query_id为纯内存变量，重启后清零，因此同一个实例中，不同事务的xid可能会相同。

但是重启后会生成新的binlog文件，因此一个binlog文件中的xid不会重复。

global_query_id 定义的长度是 8 个字节，上限为2^64-1, 到达上限后从0开始计数。



## trx_id

Xid是server层维护，innodb内部也用Xid是为了能够在innodb事务和server之间做关联。

InnoDB自己的trx_id, 是自己维护的。当开启一个事务，从max_trx_id全局变量申请，每行数据都记录了更新它的trx_id, 已此来保证数据可见性。

- 只读事务不分配trx_id
- max_trx_id 会持久化存储，重启也不会重置为 0
- 如果到达上限，会重置0，那么就可能出现脏读

## thread_id

最常见的一种id，show processlist中第一列就是。

系统保存了一个全局变量 thread_id_counter，每新建一个连接，就将 thread_id_counter 赋值给这个新连接的线程变量。

大小4字节，到达上限重置0，但线程id不会重复，因为分配时指定了不能重复。



# 其他一些问题

- 客户端连接慢

使用```mysql -uroot -p ```连接mysql时，会在连上之后查询所有的数据库，查询所有的表，然后在本地构建一个hashmap存储所有的信息。这个过程中数据库或表很多则速度就会变慢，可以使用```-A```参数来避免。

```-quick```参数则范围更大，不仅有```-A```参数的避免构建hashmap作用，同时采用mysql_use_result方式，不缓存查询集合，读取一个记录处理一个记录。这种方式可以防止本地内存占用过大，也不会记录已操作的历史命令。

但是要注意，quick采用的mysql_use_result方式，如果本地处理速度跟不上，会导致服务端发送数据变慢，影响性能。
